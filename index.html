<!DOCTYPE html>
<html>
<head>
    <title> Md Mustafizur Rahman - NAIST</title>
    <link rel="icon" type="image/png" href="image/m.png"/>
    <meta name="description" content="Md Mustafizur Rahman's Personal Page."/>
    <meta http-equiv="author" content="Md Mustafizur Rahman"/>
    <!--    <link href="css/main.css" type="text/css" rel="stylesheet"/>-->
    <link rel="stylesheet" type="text/css" href="css/main.css?v=1.0.1">
    <script>
        var userLang = navigator.language || navigator.userLanguage;
        if (userLang.startsWith('ja')) {
            window.location.href = "ja/index.html";
        }
    </script>

</head>

<body>

<div id="navigator">
    <ul>
        <li><a href="#navigator">Profile</a></li>
        <li><a href="#work_experience">Experience</a></li>
        <li><a href="#research">Research</a></li>
        <li><a href="#project">Project</a></li>
        <li><a href="#awards">Awards</a></li>

    </ul>
</div>

<div id="wrapper">
    <!-- profile block -->
    <div id="profile">
        <div id="profile_content">
            <div id="profile_content_name">
                <div id="profile_content_name_text"> Md Mustafizur Rahman</div>
                <!--				<div id = "profile_content_name_img"><img src="images/name.png", alt="Chinese Name", width="76" height="26"> </div>-->
            </div>

            <div id="profile_content_description">
                Master of Engineering Student <br/>
                <a href="https://imdl.naist.jp/">Interactive Media Design Laboratory</a> <br/>
                <a href="http://isw3.naist.jp/home-en.html">Division of Information Science</a> <br/>
                <a href="http://isw3.naist.jp/home-en.html">Graduate School of Advanced Science and Technology</a> <br/>
                <a href="https://www.naist.jp/en/"> Nara Institute of Science and Technology, Japan</a> <br/>
                <br/>
                Edu-email: rahman.md_mustafizur.rp6@naist.ac.jp <br/>
                Personal-email: mustafizur.cd@gmail.com <br/>
                <a href="files/CV_Mustafizur.pdf" target="_blank" class="special_link">Resume</a>
                <!--                <a href="files/EuroPassCV - Md Mustafizur Rahman.pdf" target="_blank" class="special_link">Europass CV</a>-->
                <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" target="_blank"
                   class="special_link">Google
                    Scholar </a>
            </div>
        </div>

        <div id="profile_image">
            <img src="image/mustafizur.jpg" , class="align-center" alt="Md Mustafizur Rahman" , width="120"
                 height="160">
        </div>
    </div>

    <div class="item_block" id="aboutme">
        <div class="item_headline">
            <h2> About Me </h2>
        </div>
        <div id="aboutme_content">
            <p>I'm a Master's student at the <a href="https://www.naist.jp/en/" target="_blank" class="light_blue_link">Nara
                Institute
                of Science and Technology, Japan</a>,
                with a background in Information Science.</p>
            <p>My work focuses on leveraging AI, AR, and VR technologies to enhance physical therapy, medical training,
                and rehabilitation.</p>
            <p>I have a passion for developing innovative solutions that combine software engineering, computer vision,
                and interactive media design.</p>
            <p>I love pixels and believe the power of simple intuition and creative thinking. </p>
        </div>
    </div>

    <div class="item_block" id="news">
        <div class="item_headline">
            <h2>News</h2>
        </div>
        <div class="item_content">
            <ul>
                <li>
                    <strong>[June 2025]</strong> During my research internship at the University of Trento, our paper
                    titled
                    <em>"Robotic Collaborative Walker with Impedance Control and Augmented Reality for Assisted Walking
                        and User Empowerment"</em>
                    was accepted to <a href="https://www.metroxraine.org/call-for-papers" target="_blank">IEEE
                    MetroXRAINE 2025</a>.
                </li>
                <li>
                    <strong>[March ~ May 2025]</strong> Successfully completed a research internship at the University
                    of Trento, Italy, focusing on mixed reality-based rehabilitation.
                    <a href="https://diinews.unitn.it/nuove-frontiere-della-realta-aumentata-realta-condivisa-tra-paziente-e-terapista/"
                       target="_blank">Research Article</a>
                </li>
                <li>
                    <strong>[January 2025]</strong> Our work on <em>"Experience Augmentation in Physical Therapy by
                    Simulating Patient-Specific Walking Motions"</em> was published at <a
                        href="https://ceur-ws.org/Vol-3907/paper12.pdf" target="_blank">APMAR2024</a>.
                </li>

                <li>
                    <strong>[October 2024]</strong> Our work on <em>"Experience Augmentation in Physical Therapy by
                    Simulating Patient-Specific Walking Motions"</em> was accepted to <a
                        href="https://sigmr.vrsj.org/apmar2024/index.html" target="_blank">APMAR2024</a>.
                </li>
            </ul>
        </div>
    </div>


    <div class="item_block" id="work_experience">
        <div class="item_headline">
            <h2> Work Experience </h2>
        </div>

        <table>
            <tr>
                <td class="work_description">
                    <a href="https://www.unitn.it/en" class="light_blue_link" target="_blank">University of Trento</a>
                    | Research Intern <br>
                    March 2025 ~ May 2025 | Via Calepina, 14, 38122 Trento TN, Italy <br>
                    &bull; Completed a research internship under the supervision of <a
                        href="http://orcid.org/0000-0003-1562-0328" class="light_blue_link" target="_blank">Professor
                    Mariolino De Cecco</a> and <a
                        href="https://scholar.google.com/citations?user=hy8o6aUAAAAJ&hl=en&oi=ao"
                        class="light_blue_link" target="_blank"> Alessandro Luchetti, PhD</a> at <b> <a
                        href="https://www.miro.ing.unitn.it/" target="_blank">MiroLab</a> </b>, focusing on the
                    development of Mixed Reality systems for industrial and rehabilitation applications.<br>
                    &bull; Developed a mixed-reality based serious game on <b>Meta Quest 3</b>, integrating a
                    collaborative robotic walker with a spatially aware AR interface.<br>
                    &bull; Designed real-time therapist-patient interactions within a co-located shared space using <b>Photon
                    Fusion</b> for networking and <b>MQTT</b> for robot communication.<br>
                    &bull; Built a marker-based <b>path drawing system</b> with avatar navigation, path validation, and
                    real-time feedback (e.g., avatar responds when the patient deviates from the path).<br>
                    &bull; Enabled gamified therapy through collectible items along the path, with <b>real-time path
                    plotting</b> to visualize planned vs. actual movement.<br>
                    &bull; Implemented a <b>content placement system</b> to simulate virtual terrains (lava, ice, sand)
                    using ray-based interaction and Unity's MRUK scene understanding.<br>
                    &bull; Validated the system through co-location between therapist and patient HMDs, synchronized
                    with an external robotic walker to support adaptive gait rehabilitation.<br>
                    <b> *** Featured in a research article published on the University of Trento website:</b>
                    <a href="https://diinews.unitn.it/nuove-frontiere-della-realta-aumentata-realta-condivisa-tra-paziente-e-terapista"
                       class="light_blue_link" target="_blank">
                        Research News - New frontiers of augmented reality: shared reality between patient and therapist
                    </a><br>
                </td>
                <td class="work_image" id="University of Trento_img">
                    <img src="image/unitrento.png" alt="University of Trento" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://www.kyoto-u.ac.jp/en" class="light_blue_link" target="_blank">Kyoto University</a>
                    | Research Collaborator <br>
                    March 2024 ~ Present | 54 Kawahara-cho, Shogoin, Sakyo-ku, Kyoto 606-8507, JAPAN <br>
                    &bull; Collaborating with professors <a
                        href="https://scholar.google.com/citations?user=Oz9_9Z8AAAAJ&hl=en" class="light_blue_link"
                        target="_blank">Goshiro Yamamoto</a>, <a
                        href="https://scholar.google.co.jp/citations?user=jhNjdXcAAAAJ&hl=ja" class="light_blue_link"
                        target="_blank">Chang Liu</a>, and <a href="https://researchmap.jp/hiro-ueshima"
                                                              class="light_blue_link" target="_blank">Hiroaki
                    Ueshima</a> from the Clinical Research Center for Medical Equipment Development.<br>
                    &bull; Engaged in research titled "Experience Augmentation in Physical Therapy by Simulating
                    Patient-Specific Walking Motions," enhancing rehabilitation outcomes through advanced simulation
                    techniques.<br>
                    &bull; Involved in multidisciplinary projects focused on optimizing rehabilitation practices in
                    physical therapy settings.<br>
                    &bull; Integrating generative AI and LLMs, such as BERT, to improve therapeutic interventions and
                    enhance patient communication.<br>
                    &bull; Leveraging Augmented Reality (AR), Virtual Reality (VR), and Mixed Reality (MR) to develop
                    interactive tools that facilitate immersive learning experiences for physical therapists by
                    simulating a wide range of impaired gait patterns.<br>
                </td>
                <td class="work_image" id="kyoto_university_img">
                    <img src="image/kyoto_uni.png" alt="Kyoto University" width="140" height="49">
                </td>
            </tr>
            <tr>
                <td class="work_description">
                    <a href="https://imdl.naist.jp/" class="light_blue_link" target="_blank">Researcher | Master's
                        Student at the Interactive Media Design
                        Lab., NAIST</a><br>
                    October 2023 ~ Present | 8916-5 Takayama-cho, Ikoma, Nara 630-0192, JAPAN <br>
                    &bull; Currently engaged in a research project titled "Experience Augmentation in Physical Therapy
                    by Simulating Patient-Specific Walking Motions," utilizing the HumanML3D dataset.<br>
                    &bull; Supervised by esteemed lab supervisor <a
                        href="https://scholar.google.com/citations?user=zlyaC60AAAAJ&hl=en" class="light_blue_link"
                        target="_blank">Professor Hirokazu Kato</a> and other Assistant Professor
                    <a href="https://scholar.google.com/citations?user=5vnFG2sAAAAJ&hl=ja" class="light_blue_link"
                       target="_blank">Taishi Sawabe</a> and <a
                        href="https://scholar.google.com/citations?user=5qcS7IoAAAAJ&hl=en" class="light_blue_link"
                        target="_blank">Isidro Butaslac</a><br>
                    &bull; Focused on developing innovative solutions that enhance physical therapy through the
                    simulation of individualized walking motions.<br>
                    &bull; Contributing to cutting-edge research aimed at improving therapeutic outcomes for patients in
                    rehabilitation settings by providing immersive 3D motion simulations.<br>
                    &bull; Leveraging expertise in Augmented Reality (AR), Virtual Reality (VR), and Mixed Reality (MR)
                    to create dynamic, patient-specific motion representations.<br>
                    &bull; Applying generative AI techniques and large language models (LLMs), including BERT, to
                    analyze and generate impaired human motion data for improved therapeutic applications.<br>
                </td>
                <td class="work_image" id="naist_img">
                    <img src="image/imd_lab.png" alt="Interactive Media Design Laboratory" width="140" height="49">
                </td>
            </tr>
            <tr>
                <td class="work_description">
                    <a href="https://talentpro.global/" target="_blank" class="light_blue_link">Talent Pro</a> | Team
                    Lead - Software Quality Assurance Engineer <br>
                    June 2022 ~ August 2023 | 109 Masjid Road, Old DOHS, Banani, Dhaka 1206, Bangladesh. <br>
                    &bull; Led the QA efforts and managed testing processes for various projects at TalentPro. <br>
                    &bull; Created and executed test plans, test cases, and designed automation test scripts.<br>
                    &bull; Conducted test execution result analysis. <br>
                    &bull; Specialized in Appium, Selenium WebDriver, TestNG, and Cucumber within Java-based automation
                    frameworks (TDD, BDD). <br>
                    &bull; Managed API testing, performance testing, security testing, and database testing using REST
                    Assured and GraphQL.
                </td>
                <td class="work_image" id="talentpro_img">
                    <img src="image/talentpro-global-logo.jpg" alt="Talent Pro" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://realezy.com/" target="_blank" class="light_blue_link">RealEzy (Singapore)</a> |
                    Software Quality Assurance Engineer <br>
                    June 2022 ~ August 2023 | Singapore-based project under TalentPro <br>
                    &bull; Hired by RealEzy, a leading Singapore real estate platform, for a dedicated QA role on their
                    project. <br>
                    &bull; Responsible for automating test processes, designing test plans, and ensuring software
                    quality through manual and automated testing. <br>
                    &bull; Worked extensively with Appium, Selenium, and Java-based automation frameworks to streamline
                    testing efforts for RealEzy's platform. <br>
                    &bull; Performed API, performance, and security testing using REST Assured, ensuring optimal
                    functionality for the platform.
                </td>
                <td class="work_image" id="realezy_img">
                    <img src="image/realEzy_Logo.svg" alt="RealEzy" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://fanfare.com.bd/" target="_blank" class="light_blue_link">Fanfare (Bangladesh)</a> |
                    Team Lead - Software Quality Assurance Engineer <br>
                    March 2023 ~ May 2023 | Bangladesh-based project under TalentPro <br>
                    &bull; Assigned to Fanfare, a social commerce platform, to ensure quality in their software releases
                    for three months. <br>
                    &bull; Developed and executed test plans, test cases, and automated testing scripts to support the
                    platform's quality assurance. <br>
                    &bull; Utilized Appium, Selenium, and Java-based automation frameworks to optimize test cycles. <br>
                    &bull; Conducted API and performance testing using REST Assured, ensuring smooth integration of new
                    features and updates.
                </td>
                <td class="work_image" id="fanfare_img">
                    <img src="image/fanfarelogo.png" alt="Fanfare" width="140" height="49">
                </td>
            </tr>
        </table>
    </div>

    <!--Research -->
    <div class="item_block" id="research">
        <div class="item_headline">
            <h2>Research </h2>
        </div>
        <!-- Walker Project -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image"><img src="image/research-img/SeriousGameImage.png" class="align-center"
                                                   alt="Robotic Collaborative Walker " width="800" height="236"/></td>
                </tr>
                <tr>
                    <td class="project_title"><a href="#" class="project_title_link">Robotic Collaborative Walker with
                        Impedance
                        Control and Augmented Reality for Assisted Walking and User Empowerment</a></td>
                </tr>
                <tr>
                    <td class="project_author">

                        <a href="http://orcid.org/0000-0003-1562-0328" class="light_blue_link"
                           target="_blank">Mariolino De Cecco<sup>*</sup></a>,

                        <a href="https://orcid.org/0000-0002-9837-083X" class="light_blue_link"
                           target="_blank">Giandomenico Nollo</a>,

                        <a href="https://scholar.google.com/citations?user=hy8o6aUAAAAJ&hl=en&oi=ao"
                           class="light_blue_link"
                           target="_blank">Alessandro Luchetti</a>,
                        <a href="https://orcid.org/0009-0006-1760-7695" class="light_blue_link"
                           target="_blank">Matteo Bonetto</a>,
                        <a href="https://orcid.org/0000-0003-2956-7652" class="light_blue_link"
                           target="_blank">Damiano Fruet</a>,
                        <a href="https://orcid.org/0009-0001-9396-0750" class="light_blue_link"
                           target="_blank">Muhammad Irtaza</a>,<br>
                        <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" class="light_blue_link"
                           target="_blank"><b>Md Mustafizur Rahman<sup>*</sup></b></a>,
                        <a href="#" class="light_blue_link"
                           target="_blank">Ryosuke Shigeto</a>,
                        <a href="https://scholar.google.com/citations?user=5qcS7IoAAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Isidro Butaslac</a>
                    </td>
                <tr>
                    <!--				<tr><td class="research_misc"><i>arXiv,</i> 2020</td></tr>-->
                <tr>
                    <td class="project_description">
                        <p>
                            We present an immersive <strong>mixed reality rehabilitation system</strong> that supports
                            <strong>therapist-guided gait training</strong> using a <strong>collaborative robotic
                            walker</strong>. The system allows therapists to draw <strong>custom walking paths</strong>
                            directly in the physical environment using <strong>Meta Quest 3</strong>, enhanced with
                            <strong>scene understanding</strong> and <strong>co-located shared space</strong>. A
                            <strong>virtual avatar</strong> (dog, cat, penguin, or deer) provides <strong>real-time
                            feedback</strong> and motivational cues as patients follow the prescribed path. The
                            integration of <strong>Photon Fusion networking</strong> and <strong>MQTT-based robot
                            communication</strong> enables synchronized interaction between therapist, patient, and
                            robot in a unified space. Through features like <strong>terrain-aware content
                            placement</strong> (lava, ice, sand) and <strong>gamified item collection</strong>, the
                            system offers a personalized, adaptive rehabilitation experience.
                        </p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p>
                            <strong>Development Overview:</strong> This system was developed using <strong>Unity3D (Meta
                            Quest 3)</strong> with extensive use of <strong>C#</strong> for real-time interaction logic.
                            <strong>Photon Fusion</strong> was used for multiplayer networking, and <strong>M2MQTT
                            (Unity)</strong> handled bidirectional communication with the robotic walker. <strong>MR
                            Utility Kit (MRUK)</strong> enabled environment scanning and spatial anchor alignment.
                            Gamification features and path tracking were implemented using <strong>LineRenderer</strong>
                            and real-time MQTT telemetry. The entire system was tested and deployed in a physical
                            therapy simulation with <strong>real robot coordination</strong> and therapist-patient role
                            synchronization.
                        </p>
                    </td>
                </tr>

                <!--                <tr>-->
                <!--                    <td class="project_appendix">-->
                <!--                        <p>Acknowledgments: This work was supported by JSPS KAKENHI Grant Number JP23K24888.</p>-->
                <!--                    </td>-->
                <!--                </tr>-->
                <tr>
                    <td class="project_appendix">
                        <!--                            <a href="#" class="project_link">project page</a> |-->
                        [<a href="https://www.metroxraine.org/call-for-papers" target="_blank" class="project_link">
                        Accepted to IEEE MetroXRAINE 2025</a>]
                        [<a href="https://drive.google.com/file/d/14QERept3Pf_4CCE0XtZ4sXwvt9nTGkkL/view"
                            target="_blank" class="project_link">
                        Demo Video</a>]
                        <!--                            <a href="#" class="project_link">video</a>-->
                    </td>
                </tr>

                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>

        <!-- Specific-Motion -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image"><img src="image/research-img/1TeaserImage.png" class="align-center"
                                                   alt="Specific Walking Motion " width="800" height="236"/></td>
                </tr>
                <tr>
                    <td class="project_title"><a href="#" class="project_title_link">Experience Augmentation in Physical
                        Therapy by
                        Simulating Patient-Specific Walking Motions</a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" class="light_blue_link"
                           target="_blank"><b>Md Mustafizur Rahman</b></a>,
                        <a href="https://scholar.google.com/citations?user=Oz9_9Z8AAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Goshiro Yamamoto</a>,
                        <a href="https://scholar.google.co.jp/citations?user=jhNjdXcAAAAJ&hl=ja" class="light_blue_link"
                           target="_blank">Chang Liu</a>,
                        <a href="https://researchmap.jp/hiro-ueshima" class="light_blue_link" target="_blank">Hiroaki
                            Ueshima</a>,
                        <a href="https://scholar.google.com/citations?user=5qcS7IoAAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Isidro Butaslac</a>,
                        <a href="https://scholar.google.com/citations?user=5vnFG2sAAAAJ&hl=ja" class="light_blue_link"
                           target="_blank">Taishi Sawabe</a>,
                        <a href="https://scholar.google.com/citations?user=zlyaC60AAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Hirokazu Kato</a>
                    </td>
                <tr>
                    <!--				<tr><td class="research_misc"><i>arXiv,</i> 2020</td></tr>-->
                <tr>
                    <td class="project_description">
                        <p>
                            We propose a novel system for <strong>physical therapy training</strong> that enhances
                            understanding of <strong>impaired gait patterns</strong> using the <strong>HumanML3D
                            dataset</strong>. Our approach combines a <strong>classification model</strong> for
                            predicting motion length from textual descriptions and a <strong>temporal variational
                            autoencoder</strong> for generating diverse 3D motion sequences. By utilizing <strong>residual
                            vector quantization</strong> and a <strong>Masked Transformer</strong>, the system ensures
                            <strong>precise and consistent motion generation</strong>. This <strong>interactive
                            tool</strong> allows therapists to simulate <strong>patient-specific movements</strong> in
                            <strong>mixed reality environments</strong>, transforming therapeutic training and
                            personalizing rehabilitation strategies.
                        </p>

                        <!--					<p>Here we rebuild a 3D animatable Roger Federer from a video of 2015 US Open Final. Please check out the dynamic versions of the results on the <a href="https://grail.cs.washington.edu/projects/vid2actor/" class="light_blue_link">project page</a>.</p>-->
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p>
                            <strong>Development Overview:</strong> In this study, I utilized <strong>Python</strong> and
                            <strong>C#</strong> to develop the application, leveraging <strong>Unity3D</strong> as my
                            development platform.
                            I incorporated <strong>FastAPI</strong> for backend services and utilized the <strong>Blender
                            Python API</strong> for the motion retargeting process to map the generated motion onto the
                            target 3D model's skeleton.
                            The development environment was set up in <strong>PyCharm</strong>, and the application was
                            deployed on the <strong>Meta Quest 3</strong> for an immersive experience.
                        </p>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p>Acknowledgments: This work was supported by JSPS KAKENHI Grant Number JP23K24888.</p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <!--                            <a href="#" class="project_link">project page</a> |-->
                        [<a href="https://ceur-ws.org/Vol-3907/paper12.pdf" target="_blank" class="project_link">
                        Paper</a>]
                        <!--                            <a href="#" class="project_link">video</a>-->
                    </td>
                </tr>

                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>
        <!-- HealOvr -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image"><img src="image/research-img/OverallArchitecture.jpg" class="align-center"
                                                   alt="Specific Walking Motion " width="800" height="236"/></td>
                </tr>
                <tr>
                    <td class="project_title"><a href="#" class="project_title_link">Virtual Reality Based Medical
                        Training Simulator and Robotic Operation System</a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" class="light_blue_link"
                           target="_blank"><b>Md Mustafizur Rahman</b></a>,
                        <a href="https://www.linkedin.com/in/md-fatin-ishmam-5567b3155/" class="light_blue_link"
                           target="_blank">Md Fatin Ishmam</a>,
                        <a href="https://scholar.google.com/citations?user=CwkzwcQAAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Md. Tanvir Hossain</a>,
                        <a href="https://scholar.google.com/citations?hl=en&user=D0cqricAAAAJ" class="light_blue_link"
                           target="_blank">Md. Emdadul Haque</a>,
                    </td>
                <tr>
                    <!--				<tr><td class="research_misc"><i>arXiv,</i> 2020</td></tr>-->
                <tr>
                    <td class="project_description">
                        This study introduces a virtual reality (VR) medical training simulator to enhance learning in
                        medical education.
                        Using 3D models, students can interactively explore human anatomy and physiology, perform
                        surgical operations, and repeatedly practice without the constraints of real human bodies.
                        Additionally, the system connects to a robotic platform, enabling skilled surgeons to perform
                        remote surgeries using VR to control robotic tools.
                        This reduces the need for patients in remote areas to travel to cities for specialized care,
                        offering an innovative solution for medical training and remote surgery.
                        <!--					<p>Here we rebuild a 3D animatable Roger Federer from a video of 2015 US Open Final. Please check out the dynamic versions of the results on the <a href="https://grail.cs.washington.edu/projects/vid2actor/" class="light_blue_link">project page</a>.</p>-->
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p><strong>Development Overview:</strong> This project leveraged <strong>C#</strong> for
                            application development and <strong>C++</strong> for the communication bridge via <strong>Firebase</strong>.
                            The <strong>Unity3D</strong> engine was employed for UI and room design, with real-time
                            <strong>video transmission</strong> over <strong>TCP/IP</strong> enabling surgeon monitoring
                            in VR.
                            <strong>Photon Network</strong> facilitated multi-user collaboration, and the robotic system
                            was controlled using <strong>Arduino Mega2560</strong>, executing commands transmitted as
                            <strong>JSON</strong> for robotic actions.</p>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <!--                            <a href="#" class="project_link">project page</a> |-->
                        [<a href="https://ieeexplore.ieee.org/abstract/document/10188546" target="_blank"
                            class="project_link">
                        Paper</a>]
                        <!--                            <a href="#" class="project_link">video</a>-->
                    </td>
                </tr>
                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>
    </div>
    <!--End Research -->

    <!--Project -->
    <div class="item_block" id="project">
        <div class="item_headline">
            <h2>Project </h2>
        </div>

        <!-- AR Pose Trainer -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                <tr>
                    <td class="project_image"><img src="image/project-img/ARPoseTrainer.png" class="align-center"
                                                   alt="Specific Walking Motion " width="800" height="236"/></td>
                </tr>

                <!--						<td class="project_image"><img src="images\digitspace.gif" align="left" alt="Digit Space" width="427" height="429" />-->
                <!--												  <img src="images\moonriver.png" align="right" alt="MoonRiver" width="332" height="429" />-->
                <!--						</td>-->
                </tr>
                <tr>
                    <td class="project_title"><a
                            href="https://drive.google.com/file/d/1GU9YgjXGqyFPv7kpbDkelXkG7q63cEy_/view"
                            target="_blank" class="project_title_link">ARPoseTrainer: Real-Time Feedback for Motor
                        Rehabilitation Using Augmented Reality</a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <b>Md Mustafizur Rahman</b>
                    </td>
                <tr>
                <tr>
                    <td class="project_description">
                        <p>The depicted system integrates Augmented Reality (AR) to support motor rehabilitation by
                            enabling real-time motion analysis and feedback.
                            A depth sensor(Azure Kinect) captures the patient's movement data, which is processed on a
                            PC to generate skeletal tracking visualizations.
                            These data are transmitted via UDP/IP to an AR device, such as a HoloLens, allowing
                            therapists and patients to interact with virtual avatars in real time.
                            The system offers immediate feedback on pose accuracy and performance scores, enhancing
                            rehabilitation by providing immersive,
                            precise guidance and monitoring for motor skill improvement.</p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p><strong>Development Overview:</strong>
                        <p>This system utilizes <strong>Augmented Reality (AR)</strong> for motor rehabilitation,
                            providing real-time motion analysis and feedback.
                            <strong>Azure Kinect</strong> captures patient movements, processed in <strong>C#</strong>
                            to create skeletal tracking visualizations transmitted via <strong>UDP/IP</strong> to
                            devices like the <strong>HoloLens</strong>.
                            Instant feedback on pose accuracy and performance metrics is provided, while a <strong>Laravel
                                REST API</strong> in <strong>PHP</strong> and a <strong>MySQL</strong> database enable
                            score storage and personalized performance data access through a web interface.</p>


                </tr>
                <tr>
                    <td class="project_appendix">[
                        <a href="https://drive.google.com/file/d/1GU9YgjXGqyFPv7kpbDkelXkG7q63cEy_/view" target="_blank"
                           class="project_link">video</a> |
                        <a href="https://github.com/mustafizur-r/arposetrainerapp-live" target="_blank"
                           class="project_link">code</a>]
                    </td>
                </tr>

                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>

        <!-- End AR Pose Trainer -->
        <!-- Handwriting recognition -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                <tr>
                    <td class="project_image"><img src="image/project-img/HandwritingREcognition.png"
                                                   class="align-center"
                                                   alt="Hand Writing Recognition" width="800" height="236"/></td>
                </tr>

                <!--						<td class="project_image"><img src="images\digitspace.gif" align="left" alt="Digit Space" width="427" height="429" />-->
                <!--												  <img src="images\moonriver.png" align="right" alt="MoonRiver" width="332" height="429" />-->
                <!--						</td>-->
                </tr>
                <tr>
                    <td class="project_title"><a
                            href="#"
                            target="_blank" class="project_title_link">Handwrite AI: Smart OCR for Handwritten Notes to
                        Digital Text
                    </a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <b>Md Mustafizur Rahman</b>
                    </td>
                <tr>
                <tr>
                    <td class="project_description">
                        <p>Handwriting to Text OCR application converting scanned handwritten notes into digital text
                            which is available for edits, search and stored in any platform.
                            The application uses advanced Optical Character Recognition (OCR) techniques to accurately
                            recognize and convert handwritten text from images or scanned documents into editable digital
                            text.
                            It can handle various handwriting styles, making it a versatile
                            tool for students, professionals, and anyone who needs to digitize handwritten content.
                        </p>
                        <p>Developed Year: 2019</p>
                    </td>

                </tr>

                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>
        <!-- Handwriting recognition -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                <tr>
                    <td class="project_image"><img src="image/project-img/SignatureDetection.jpg"
                                                   class="align-center"
                                                   alt="Signature Recognition" width="800" height="236"/></td>
                </tr>

                <!--						<td class="project_image"><img src="images\digitspace.gif" align="left" alt="Digit Space" width="427" height="429" />-->
                <!--												  <img src="images\moonriver.png" align="right" alt="MoonRiver" width="332" height="429" />-->
                <!--						</td>-->
                </tr>
                <tr>
                    <td class="project_title"><a
                            href="#"
                            target="_blank" class="project_title_link">Signature Authentication System: Improving Accuracy with AI and Biometrics
                    </a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <b>Md Mustafizur Rahman</b>
                    </td>
                <tr>
                <tr>
                    <td class="project_description">
                        <p>Recognition and verification of given signature by using image Processing and Machine Learning.
                            The system uses a combination of image processing techniques and machine learning algorithms to
                            accurately recognize and verify signatures, ensuring the authenticity of documents and preventing
                            forgery.</p>
                        <p>Developed Year: 2019</p>
                    </td>
                </tr>

                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">back to top</a></div>
        </div>
    </div>
    <!--End Project -->


    <!--Awards -->
    <div class="item_block" id="awards">
        <div class="item_headline">
            <h2>Awards and Achievements</h2>
        </div>

        <div class="cv_item_content" id="award_content">
            <div class="award_item">
                <table class="award_table">
                    <thead class="award_table_head">
                    <tr>
                        <th scope="col" class="awards_year_head">Year</th>
                        <th scope="col" class="award_number">Award/Recognition</th>
                        <th scope="col" class="award_title_head">Title</th>
                        <th scope="col" class="award_country_head">Country</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr>
                        <td class="award_number">March-May, 2025</td>
                        <td class="award_number">Erasmus+ ICM<br></td>
                        <td class="award_title">Erasmus International Credit Mobility (ICM) Exchange Programme at
                            University of Trento
                        </td>
                        <td class="award_country">Italy</td>
                    </tr>
                    <tr>
                        <td class="award_number">2023-2025</td>
                        <td class="award_number">Monbukagakusho (MEXT) Scholarship</td>
                        <td class="award_title">MEXT Scholarship Master's student at NAIST</td>
                        <td class="award_country">Japan</td>
                    </tr>
                    <tr>
                        <td class="award_number">2023</td>
                        <td class="award_number">Tech Genius Awards</td>
                        <td class="award_title"> Recognized for delivering the Best Performance as a Team Leader at
                            TalentPro
                        </td>
                        <td class="award_country">Bangladesh</td>
                    </tr>
                    <tr>
                        <td class="award_number">2019</td>
                        <td class="award_number">1<sup>st</sup> Runner-Up at the IEEE RAS Hackathon</td>
                        <td class="award_title">BUET Winter School IEEE RAS Hackathon</td>
                        <td class="award_country">Bangladesh</td>
                    </tr>
                    <tr>
                        <td class="award_number">2019</td>
                        <td class="award_number">1<sup>st</sup> Runner-Up at the Robotics Exhibition and Competition
                        </td>
                        <td class="award_number">LICT-JOB Fair Project Showcasing</td>
                        <td class="award_country">Bangladesh</td>
                    </tr>
                    </tbody>
                </table>
                <div class="back_to_top">
                    <a href="#navigator" class="black_link">back to top</a>
                </div>
            </div>
        </div>
    </div>
    <!--End Awards -->

    <!-- Training Courses -->
    <div class="item_block" id="training_courses">
        <div class="item_headline">
            <h2>Training Courses</h2>
        </div>

        <div class="cv_item_content" id="training_courses_content">
            <div class="training_item">
                <table class="training_table">
                    <thead class="training_table_head">
                    <tr>
                        <th scope="col" class="training_year_head">Year</th>
                        <th scope="col" class="training_title_head">Course Title</th>
                        <th scope="col" class="training_description_head">Coursework</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr>
                        <td class="training_year">MAY - JUNE, 2019</td>
                        <td class="training_title">AR, VR, MR Technology Course</td>
                        <td class="training_description">
                            What is virtual reality (VR), Augmented reality (AR), and mixed reality (MR) technologies,
                            devices, principles of operation, applications, and services in AR, VR, and MR systems.
                            Practical display and use (Oculus Rift CV1/S, Oculus Quest, MS HoloLens, Samsung Gear VR,
                            Google Cardboard, etc.)
                        </td>
                    </tr>
                    <tr>
                        <td class="training_year">JANUARY-FEBRUARY, 2020</td>
                        <td class="training_title">Skill Development for Arduino & Robotics</td>
                        <td class="training_description">
                            Arduino Basic to Pro, I2C, LCD, OLED, 7-Segment, Dot matrix display, DC, LDR and MQ-135 Gas
                            sensor, RTC and PIR sensor, RFID reader, 4x4 Keypad and IR sensor, UART and GPS, GSM Module,
                            PWM and Motor Driver, Humidity and Temperature sensor, Ultrasonic sensor, Node MCU, Wi-Fi.
                        </td>
                    </tr>
                    <tr>
                        <td class="training_year">FEBRUARY – APRIL, 2019</td>
                        <td class="training_title">April Mobile Game & Application Course</td>
                        <td class="training_description">
                            Effective and Creative Mobile Game Design, Production, and Delivery.
                        </td>
                    </tr>
                    </tbody>
                </table>
                <div class="back_to_top">
                    <a href="#navigator" class="black_link">back to top</a>
                </div>
            </div>
        </div>
    </div>
    <!-- End Training Courses -->

</div>
</body>

</html>
